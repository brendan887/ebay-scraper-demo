# CSE 151A Group Project

## Milestone 2 - Data Exploration and Initial Processing

Since we are scraping our own data, we can design our own dataset as a preprocessing step. This way, we ensure that the dataset is representative of cards that we are interested in and has a sufficient representation of cards with different features. These features include but are not limited to:

- Card type (standard vs. trainer)
- Art size (half art vs. full art)
- Special variant (EX, GX, VMAX, etc.)

We have decided to collect card images for **the top 10 most valuable cards for each set** as of 11/3/24, with a total of XX different cards. The complete card list can be found in `config.py`. This query provides a good distribution of cards as it automatically includes cards for each generation and the special variants for each of these generations.

For each card, we have collected 2 images for each of the following classes, for a total of XX cards for each class:

- PSA 10
- PSA 9
- PSA 8
- PSA 7
- PSA 6 and below

This ensures that the distribution of data between classes is even.

Additional distribution information:

| Feature               | Count |
| --------------------- | ----- |
| Pokemon (non-Trainer) | X     |
| Trainer               | X     |
| Full Art              | X     |
| Half Art              | X     |
| Total                 | X     |

As we are handling image data, each image has pixel values ranging from 0-255. Min-max normalization is used to scale values to 0-1.

Dataset can be found here: XX

## Milestone 1 - Abstract

When a collector wants to validate the authenticity and quality of a trading card, they send in their cards to an authenticating company who will give the card a grade, usually from 1-10. The objective of this project is to develop a machine learning model that accurately predicts the grade/quality of a Pok√©mon trading card based on its image. The approach involves collecting a comprehensive dataset of images of graded cards, each annotated with its official grade. Data preprocessing techniques such as cropping to isolate the card and perspective transformation to correct for angular distortions will be used to improve the quality of the data. One solution is to train a supervised CNN to learn the visual features associated with different grading levels, such as centering, whitening, and scratching. This model aims to output a confidence score for the card's grade when presented with a new image. Another solution that will be explored is performing feature extraction and distance calculation from a perfect example of the card. These models can help evaluate the efficacy of either solution and advise if a card is worth grading.
